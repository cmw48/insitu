"""
INSITU - Experiment with Python and PubMed XML
Using iterparse to return information from large XML files generated by PubMed
This program will (eventually) find PubMed references "in situ" in the PubMed database.
Copyright (C) 2010 Chris Westling, Mann Library ITS, Cornell University

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.

WARNING: work in progress - test on small files first!
TODO: build GUI, better exception handling, code cleanup and optimization
INFO: Chris Westling Mann Library ITS, Cornell University, Ithaca, NY
E-MAIL: cmw48@cornell.edu
"""

# import modules
from lxml import etree
import copy
import codecs
import os
import sys, traceback
import datetime  
import time
import pprint
import urllib
from xml.dom import minidom
#import urllib2  # ?dev - investigate advantages to using newer library

#declare globals up top for easy editing
calsinfile = 'allCALSpubmed100118.xml'               # VET PubMed xml filename
weillinfile = 'WeillPubMed100119.xml'                # WEILL PubMed xml filename
curbdinfile = 'allCornellIthacaWeill.xml'            # ALL CU RBD PubMed xml filename
ufrbdinfile = 'UnivofFloridaRBD.xml'                 # ALL UF RBD PubMed xml filename
vetinfile = 'allVETpubmed100118.xml'                 # VET PubMed xml filename
weillnamefile = 'allweillpeoplewithemail.xml'        # SPARQL generated xml, list of WEILL VIVO URI, name, email
calsnamefile = 'allCALSpeoplewithemail.xml'          # SPARQL generated xml, list of CALS VIVO URI, name, email
vetnamefile = 'allvetpeoplewithemail.xml'            # SPARQL generated xml, list of VET VIVO URI, name, email
emailnamefile = 'allpeopleinVIVOwithemail2.xml'      # SPARQL generated xml, list of ALL VIVO URI, name, email
outputtextfile = 'insituTEXTOUT 0.3.5h.txt'
datatextfile = 'insituDATAOUT 0.3.5h.txt'
outputXMLfile = 'insituXMLOUT0.3.5h.xml'
exceptXMLfile = 'insituXMLEXCEPT0.3.5h.xml'
nameXMLfile = 'insituNAMEXMLOUT0.3.5h.xml'
# here's the 'adjustment knob' for tweaking which pubs we keep and which we send to the exceptions report
# ?dev - convert to object to avoid passing variable between four different functions
squelch = 65
# if the partialmatch switch is set to true, allows partial last name matches
# ?dev - much more useful if matching terms instead of names, remove?
partialmatch = False
numrecs = 0


class SearchAuthorName:
    ''' SearchAuthorName class: provides object ref for variables created to house the name parts from VIVO.  For each
    author in NameList, populate the following variables for the purposes of searching through the PubMed
    XML one time.  Output data based on matches via lambda statement, and clear these variables in preparation
    for the next searchauthor.
    ?dev- how to expand this class to hold persistent metrics about each searchauthor?
    ?dev- searchname is a list of lists of all search author URI, Name and Email-- leverage this for search
    author metrics, consider a separate class for one-shot placeholder object refs?'''
    searchname = []   
    lastname = ""
    lastinit = ""
    firstinit = ""
    midinit = ""
    firstname = ""
    middlename = ""
    suffix = ""
    authemail = ""
    authuri = ""
    authname = ""

    
class FoundAuthorName:
    ''' FoundAuthorName class not currently in use: added for possible speed and ease comparisons.
    This class provides object ref for variables created to house the name parts from VIVO.  For each
    author in NameList, populate the following variables for the purposes of searching through the PubMed
    XML one time.  Output data based on matches via lambda statement, and clear these variables in preparation
    for the next searchauthor.
    ?dev- how to expand this class to hold persistent metrics about each searchauthor?
    ?dev- searchname is a list of lists of all search author URI, Name and Email-- leverage this for search
    author metrics, consider a separate class for one-shot placeholder object refs?'''
    lastname = ""
    forename = ""
    initials = ""
    firstinit = ""
    midinit = ""
    firstname = ""
    middlename = ""
    authposn = ""
    numofPMID = 0
    PMIDlist = []
    
class TempAuthorName:
    ''' TempAuthorName class used to hold name parts of authors not related to a target author in a given publication.
    For each author in a PubMed reference, TempAuthorName is populated as we sift through the authorlist, looking for
    the author that caused the lastname match. 
    ?dev- how much information should be retained about non-target, non-match authors in pubs where we have a match?
    ?dev- add a process to find other co-authors that exist in the namelist!
    ?dev- what other data fields belong here?'''
    lastname = ""
    forename = ""
    initials = ""
    firstinit = ""
    midinit = ""
    firstname = ""
    middlename = ""
    authposn = ""


class XMLnodes:
    newroot = etree.Element('MedlineCitation2')
    articlenode = etree.SubElement(newroot, 'Article')
    PMIDnode = etree.SubElement(articlenode, 'PMID')
    abstractnode = etree.SubElement(articlenode, 'Abstract')
    arttitlenode = etree.SubElement(articlenode, 'ArticleTitle')      
    journalnode = etree.SubElement(articlenode, 'Journal')
    affilnode = etree.SubElement(articlenode, 'Affiliation')
    affilemailnode = None
    issnnode = etree.SubElement(journalnode, 'ISSN')
    journalissuenode = etree.SubElement(journalnode, 'JournalIssue')
    volnode = etree.SubElement(journalissuenode, 'Volume')
    issuenode = etree.SubElement(journalissuenode, 'Issue')
    pubdatenode =  etree.SubElement(journalissuenode, 'PubDate')
    medlinedatenode =  etree.SubElement(journalissuenode, 'MedlineDate') 
    journalyearnode =  etree.SubElement(pubdatenode, 'Year')
    journalmonthnode =  etree.SubElement(pubdatenode, 'Month')
    journaltitlenode = etree.SubElement(journalnode, 'Title')
    journalabbrnode = etree.SubElement(journalnode, 'ISOAbbreviation')
    authorlistnode = etree.SubElement(articlenode, 'FoundAuthorList')
    authornode = etree.SubElement(authorlistnode, 'FoundAuthor')
    vivoURInode = etree.SubElement(authornode, 'vivoURI')       
    lastnode = etree.SubElement(authornode, 'LastName')
    forenamenode = etree.SubElement(authornode, 'ForeName')
    initnode = etree.SubElement(authornode, 'Initials')
    emailnode = etree.SubElement(authornode, 'Email')
    authposnode = etree.SubElement(authornode, 'AuthorPosition')
    scorenode = etree.SubElement(authornode, 'MatchProb')    

    
    
class MyError(Exception):
    ''' MyError class is for rudimentary exception and error handling.
    ?dev - expand error handling during transition to GUI?'''
    def __init__(self, value):
        self.value = value
    def __str__(self):
        return repr(self.value)

class Output:
    ''' Output class provides object support for output strings.  Each output string is appended to a list,
    and then written to an output file with join().  Output files are human readable text reports detailing
    record matches.
    ?dev- enhance reports with CSV output so metrics can be easily brought into Excel, mySQL'''
    header = []
    authtext = []
    rectext = []
    datatext = [] 
    footer = []

class Counts:
    ''' Counts class provides object refs for global count variables
    ?dev- expand counts to include metrics that we want to track through the ingest and output process.
    ?dev- find and clean up all count incrementors and zero points'''
    match = 0 
    recs = 0
    auth = 0
    searchauth = 0
    allauth = 0
    score = 0
    lastmatch = 0
    timesthru = 0
    
class Flags:
    ''' Flags class - Originally designed for Object reference for global boolean variables
    ?dev- isMatch is deprecated, and needs to be replaced/removed.
    ?dev-  flags could be used for centralization of scoring/weighting process'''
    isMatch = False
    artHasEmail = False
    fullemailmatch = False
    partemailmatch = False
    univemailmatch = False
    firstinitmatch = False
    bothinitmatch = False
    forenamematch = False

def getScore():

    if Flags.fullemailmatch <> True:
        if Flags.forenamematch == True:
            Counts.score += 50
            #print "forename"
        else:
            pass
        if Flags.partemailmatch == True:
            Counts.score += 15
            #print "partemail"
        else:
            pass
        if Flags.univemailmatch == True:
            Counts.score += 20
            #print "univemail"
        else:
            pass
        if Flags.firstinitmatch == True:
            Counts.score += 20
            #print "firstinit"
        else:
            pass
        if Flags.bothinitmatch == True:
            Counts.score += 25
            #print "bothinit"
        else:
            pass
    else:
        Counts.score = 99   
    #reset flag data
    Flags.partemailmatch = False
    Flags.univemailmatch = False 
    Flags.firstinitmatch = False   
    Flags.bothinitmatch = False 
    Flags.forenamematch  = False
    Flags.fullemailmatch = False

    return str(Counts.score)
    
def write_names_node(xmlout, nameentry):
    '''write_names_node function is currently responsible for taking each SearchAuthorName itemlist "nameentry" (comprised
    of [URI, Namestring, Emailstring], and appending that to Object SearchAuthorName.searchname.
    ?dev - needs to be expanded for clean XML output of "converted and augmented" searchauthor data from VIVO
    '''
    #if node is not None:
        #if node.text == 'MedlineCitation2':
        #    xmlout.write(etree.tostring("\n\n", encoding='utf-8',pretty_print=True))
        #    xmlout.write(etree.tostring(node, encoding='utf-8',pretty_print=True))
        #else:
        #     xmlout.write(etree.tostring(node, encoding='utf-8',pretty_print=True))
    #write to list of lists
    SearchAuthorName.searchname.append(nameentry)
    
def write_pubs_node(xmlout, xmlexc, squelch, node):
    '''write_pubs_node function is responsible for writing each found pub xml node to an output file via
    serialize_with_xpath() and PMrecs().  v0.3.3: expanded to allow "good" pubs to go to xmlout and "bad" pubs to go to xmlexc.
    The "knob" for tuning this output is Counts.score.
    The squelch argument alloes the good/bad pubs "knob" to be tuned remotely
    ?dev - more generic (need a root node variable for if node.text)
    ?dev - pretty_print not quite formatting exactly how we'd like'''
    if node is not None:
        if Counts.score > squelch:
            if node.text == 'MedlineCitation2':
                xmlout.write(etree.tostring("\n\n", encoding='utf-8',pretty_print=True))
                xmlout.write(etree.tostring(node, encoding='utf-8',pretty_print=True))
            else:
                xmlout.write(etree.tostring(node, encoding='utf-8',pretty_print=True))
        else:
            if node.text == 'MedlineCitation2':
                xmlexc.write(etree.tostring("\n\n", encoding='utf-8',pretty_print=True))
                xmlexc.write(etree.tostring(node, encoding='utf-8',pretty_print=True))
            else:
                xmlexc.write(etree.tostring(node, encoding='utf-8',pretty_print=True))


def fast_iter(context, func):
    '''fast_iter function calls lambda functions from PMrecs() and getNameRecs and clears variables and elements for memory efficiency,
    increments record count, and returns nothing'''
    Counts.recs = 0
    print "initiating fast_iter function..."
    for event, elem in context:
        func(elem)
        Counts.recs += 1
        elem.clear()
        while elem.getprevious() is not None:
            del elem.getparent()[0]
    del context
    print ("fast_iter records count is %s" % str(Counts.recs))

    
def getNamerecs(namefile, namexmlout):
    '''getNameRecs function calls lambda function to parse namedata from VIVO xml, clears variables and
    elements for memory efficiency.  Returns message text to __main__ for user friendliness.
    ?dev - clean up need for unused arguments'''
    # use xpath expressions to find name matches in PubMed records data from XML
    #pred1 = 'contains(text(),"'
    #pred2 = '.=("'
    #pred3 = '")'

    xp1 = etree.XPath("child::binding")  
    xp2 = etree.XPath("child::binding/uri")
    xp3 = etree.XPath("child::binding/literal")
    print "processing names..."
    context = etree.iterparse(namefile, events=('end',), tag="result")
    fast_iter(context, lambda elem: write_names_node(namexmlout, process_names(elem, xp1, xp2, xp3)))
    namerecstatus = "all names processed."
    return namerecstatus
        
def process_names(elem, xp1, xp2, xp3):
    '''NOT BEING CALLED RIGHT NOW...process_names function - in this case the source is our VIVO SPARQL RS_XML, with top level element <Result> defining each record.
    We are applying pre-compiled XPath classes in an effort to bring each name in and populate the SearchName object.
    ?dev - can I find a way to rewrite and combine this function with serialize_with_xpath?
    '''

    nameroot = etree.Element('namefile')
    result = elem
    numresult = len(elem)
    #numresult should be the number of people entries in the file
    nameitems = elem.getchildren()
    numnameitems = len(nameitems)
    #numnameitems is the number if binder elements in this result tag
    bindtag = xp1(elem)
    items = []
    for y in range(numnameitems):
        datatext = ""
        bindattrib = (bindtag[y].get("name"))
        datanode = bindtag[y].getchildren()
        dataitems = len(datanode)
        for d in range(dataitems):
            datatext = datanode[d].text
            if datatext == "":
                datatext = "NODATA"
            if datatext == " ":
                datatext = "BLANK"    
        nameentry = []
        items.append(datatext)
    nameentry = items
    
    return nameentry
 
def getPMRecordCount(infile):
    context = etree.iterparse(infile, events=('end',), tag='MedlineCitation')
    fast_iter(context, lambda elem: returnPMCount(elem))
 
def returnPMCount(elem):
    '''?dev- this seems really ridiculous, but I can't figure out how to return the function value from the lambda.'''
    pmcount = len(elem)
    return pmcount


def getPMrecs(pubmedrec, xmlout, xmlexc, squelch, partialmatch):
    '''getPMrecs function calls lambda function in PMrecs() and clears variables and elements for memory efficiency'''

    # use xpath expressions to find name matches in PubMed records data from XML
    pred1 = 'contains(text(),"'
    pred2 = '.=("'
    pred3 = '")'
    #if partialmatch == True:
    #    lastnamesearch = pred1 + SearchAuthorName.lastname + pred3
    #else:
    #    lastnamesearch = pred2 + SearchAuthorName.lastname + pred3
    #next line for testing
    lastnamesearch = pred2 + SearchAuthorName.lastname + pred3
    forenamesearch = pred2 + SearchAuthorName.firstname + pred3
    firstinitsearch = pred2 + SearchAuthorName.firstinit + pred3
    #print predicatetext
    #?dev- reorder xp1-4 here so they make better sense
    xp1 = etree.XPath("child::Article/AuthorList/Author/LastName[" + lastnamesearch + "]")
    #xp1 = etree.XPath("child::Article/AuthorList/Author/LastName[contains(text(), 'Ab')]")
    xp2 = etree.XPath("child::PMID")
    xp3 = etree.XPath("child::Article/AuthorList")
    xp4 = etree.XPath("child::Article/AuthorList/Author/Forename[" + forenamesearch + "]")    
    xp5 = etree.XPath("child::Article/AuthorList/Author/Initials[" + firstinitsearch + "]")
    context = etree.iterparse(stringIO(pubmedrec), events=('end',), encoding='utf-8', tag='MedlineCitation')
    fast_iter(context, 
       lambda elem: write_pubs_node(xmlout, xmlexc, squelch, serialize_with_xpath(elem, xp1, xp2, xp3, xp4, xp5)))
  

def serialize_with_xpath(elem, xp1, xp2, xp3, xp4, xp5):
    '''serialize_with_xpath function: takes our source <PubmedArticle> element and apply two pre-compiled XPath classes.
    Return a node only when we have a last name match.
    ?dev - rewrite (and rename) this function and break up separate functionalities
    ?dev - better counts for metrics
    ?dev - what was matchstring for, other than troubleshooting?
    '''
    #clear variables (?dev- examine for orphans?)
    gofish = -1
    searchnamelist = xp1(elem)
    PMIDlist = xp2(elem)
    Authlist = xp3(elem)
    forenamelist = xp4(elem)
    firstinitlist = xp5(elem)
    dataresults= []
    results = []
    #if last name is a match then trawl through database xml file to find matches for other name parts
    if searchnamelist:
        if forenamelist:
            gofish = 1
        elif firstinitlist:
            gofish = 1
        else:
            gofish = 0

    if gofish == 1:
        Counts.auth = 0
        lastmatch = -1
        initmatch = -1
        matchstring = ""
        dataresults= []
        results = []

        PMIDnode = None
        vivoURLnode = None
        authlastname = []
        authforename = []
        authinitials = []
        foundauthorname = ""
        lastnamelist = []
        abstract = []
        abstractnode = None
        arttitle = []
        arttitlenode = None
        numauthors = 0
        FoundAuthorName.forename = ""
        FoundAuthorName.initials = "" 
        Counts.score = 0
        Counts.lastmatch += 1
        #setup Xpath statements
        affilpath = etree.XPath("child::Article/Affiliation")
        lnamepath = etree.XPath("child::Article/AuthorList/Author/LastName")
        fnamepath = etree.XPath("child::Article/AuthorList/Author/ForeName")
        initpath = etree.XPath("child::Article/AuthorList/Author/Initials")
        #find authorparts from PubMed Authorlist
        lastnamelist = lnamepath(elem)
        initialslist = initpath(elem)
        forenamelist = fnamepath(elem)
        numauthors = len(lastnamelist)
        numforename = len(forenamelist)
        numinit = len(initialslist)
        affil = affilpath(elem)
        affiltext = affil[0].text 
        #pull email from affiliation string
        emailteststartpos = affiltext.rfind(" ")
        emailstring = affiltext[emailteststartpos :].strip()
        atpos = emailstring.find("@")
        if atpos > 0:
            # the affiliation string has an email at the end
            Flags.artHasEmail = True
            # when we write this pub to an XML file, break out this string as <Affiliation Email>
            # if email exists in VIVO record, look at email first
            if SearchAuthorName.authemail <> "":
                # use lowercase for both strings to ensure good match (some PubMed records use all caps = no match)
                # full email match
                if emailstring.lower() == SearchAuthorName.authemail.lower():
                     #Counts.score += 100
                     # "full email match"
                     Flags.fullemailmatch = True
                     Flags.isMatch = True
                else:  
                    # look for partial email match 
                    emailfirstthree = emailstring[:3].lower()
                    SearchAuthorName.lastinit = SearchAuthorName.lastname[:1]
                    threeinit = SearchAuthorName.firstinit + SearchAuthorName.midinit + SearchAuthorName.lastinit
                    threeinitstring = threeinit.lower()
                    #print PMIDlist[0].text.encode('utf-8') + " : " + SearchAuthorName.authemail + " : " + emailstring
                    if emailstring[-11:].lower() == "cornell.edu":
                        Flags.univemailmatch = True
                        #Counts.score += 5
                        # print "partial email match: 5 for @cornell"
                        if emailfirstthree == threeinitstring:
                            Flags.partemailmatch = True
                            Flags.isMatch = True
                            #Counts.score += 30
                            #print "partial email match: 15 for initials match first 3 email"
                        else:  
                            pass                
                    else:
                        pass
            else:
                # no email in VIVO record
                pass
        else:
            # no email found in PubMed affil string
            Flags.artHasEmail = False
        atpos = -1

        #check for a full initial match
        #assume that each pub has (numauthors) authors, based on the premise that LastName is always present
        #COUNTS: "This pub has " + str(numauthors) + " authors."
        #cycle through authors starting with author[1] to find match
        for m in range(numauthors):
            if SearchAuthorName.lastname == lastnamelist[m].text:      # is this the author we got a lastname match on?
                lastmatch = m                                          # set lastmatch flag to remember which one
                #since initials or forename tags may not appear in some PubMed records, test and set values
                #if numauthors <> numforename:
                #    if numauthors <> numinit:               # if both forename and initials are missing
                #        TempAuthorName.forename = "missing forename element!"
                #        TempAuthorName.initials = "missing initial element!"
                #    else:                                      # if only forename is missing
                #        TempAuthorName.forename = "missing forename element!"
                #        TempAuthorName.initials = initialslist[m].text    
                #elif numauthors <> numinit:                     # if initials is missing
                #    TempAuthorName.forename = forenamelist[m].text
                #    TempAuthorName.initials = "missing initial element!"
                #else:
                #    TempAuthorName.forename = forenamelist[m].text
                #    TempAuthorName.initials = initialslist[m].text
                

                fnamelen = len(SearchAuthorName.firstname)
                shortforename = TempAuthorName.forename[:fnamelen]
                if shortforename == SearchAuthorName.firstname:
                    FoundAuthorName.forename = shortforename
                    Flags.forenamematch = True
                    Flags.isMatch = True
                    initmatch = m
                elif TempAuthorName.initials.strip() == SearchAuthorName.firstinit:
                    FoundAuthorName.initials = TempAuthorName.initials.strip()
                    initmatch = m
                    Flags.firstinitmatch = True
                    Flags.isMatch = True
                else:
                    Flags.isMatch = False
                if TempAuthorName.initials.strip() == SearchAuthorName.firstinit + SearchAuthorName.midinit:         #
                        FoundAuthorName.initials = TempAuthorName.initials.strip()
                        initmatch = m
                        Flags.bothinitmatch = True
                        Flags.isMatch = True
                else:
                    Flags.isMatch = False
            else:
                # not the author we wanted
                # grab other author data here
                pass
        if Flags.isMatch == False:
            dataresults.append("%s, 0, %s, %s, %s, %s, %s, %s, %s, 0, 0.\n" % (PMIDlist[0].text, SearchAuthorName.lastname, Counts.lastmatch, Counts.match, FoundAuthorName.forename, FoundAuthorName.initials, SearchAuthorName.firstname, SearchAuthorName.middlename))
            #FoundAuthorName.forename = ""
            #FoundAuthorName.initials = "" 
    else:
        matchstring = "NO MATCH"
        #not a last name match
        lastmatch = -1
        found = False
        Flags.isMatch = False

    if Flags.isMatch == True:
        print "matching..."
        Counts.match += 1
        atpos = -1
        #print str(Counts.match)
        matchstring = "MATCH"

        # if we are going to write this pub to GOOD or BAD, land here.
        # setup XML output
        # ?dev - seems like this could be managed in a different function, as long as we build class objects for variables to be saved
        # ?dev - this root element name needs to be a variable to allow renaming when not Medline

        abstractpath = etree.XPath("child::Article/Abstract/AbstractText")
        journalabbrpath = etree.XPath("child::Article/Journal/ISOAbbreviation")
        journalyearpath = etree.XPath("child::Article/Journal/JournalIssue/PubDate/Year")
        arttitlepath = etree.XPath("child::Article/ArticleTitle")
        abstract = abstractpath(elem)
        journalabbr = journalabbrpath(elem)
        arttitle = arttitlepath(elem)
        journalyear = journalyearpath(elem)
        if len(journalyear) <> 0:
            journalyeartext = journalyear[0].text
        else:
            journalyeartext = "NO YEAR"

        XMLnodes.affilnode.text = affiltext
        if Flags.artHasEmail == True:
            XMLnodes.affilemailnode = etree.SubElement(XMLnodes.articlenode, 'AffiliationEmail')
            XMLnodes.affilemailnode.text = emailstring
        else:
            #no email string
            pass
        XMLnodes.PMIDnode.text = PMIDlist[0].text
        #print "PMID" + PMIDnode.text

        if len(abstract) <> 0: 
            abstracttext = abstract[0].text
        else:
            abstracttext = "NO ABSTRACT AVAILABLE"
        XMLnodes.abstractnode.text = abstracttext    

        if len(journalabbr) <> 0: 
            journalabbrtext = journalabbr[0].text
        else:
            journalabbrtext = "NO JOURNAL ABBR. AVAILABLE"
        XMLnodes.journalabbrnode.text = journalabbrtext

        if len(arttitle) <> 0:
            arttitletext = arttitle[0].text
        else:
            arttitletext = "NO ARTICLE TITLE AVAILABLE"
        XMLnodes.arttitlenode.text = arttitletext    

        for c in Authlist:

            Counts.auth += 1
            XMLnodes.vivoURInode.text = SearchAuthorName.authuri           
            XMLnodes.lastnode.text = SearchAuthorName.lastname
            XMLnodes.forenamenode.text = FoundAuthorName.forename
            XMLnodes.initnode.text = FoundAuthorName.initials
            XMLnodes.emailnode.text = SearchAuthorName.authemail    
            XMLnodes.authposnode.text = str(initmatch+1)
            XMLnodes.journalyearnode.text = journalyeartext
            XMLnodes.scorenode.text = getScore()
    
            #newroot.append((c))      #tacks the full author list onto the xml  

        #for x in range(len(lastnamelist)):
        #print ('%s. %s,%s' % (x, lastnamelist[x].text, initials))
        #print "matching author is number " + str(initmatch)
        found = True
        foundauthorname = ("%s. %s, %s (%s)" % (initmatch+1,  SearchAuthorName.lastname, FoundAuthorName.initials, FoundAuthorName.forename))
        results.append("%s %s (%s%s) %s (%s percent)\n" % (XMLnodes.PMIDnode.text, foundauthorname, SearchAuthorName.firstinit, SearchAuthorName.midinit, matchstring, Counts.score))
        dataresults.append("%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s.\n" % (XMLnodes.PMIDnode.text, str(initmatch+1), SearchAuthorName.lastname, Counts.lastmatch, Counts.match, SearchAuthorName.firstinit, SearchAuthorName.midinit, SearchAuthorName.firstname, SearchAuthorName.middlename, journalyeartext, Counts.score))
        print "waiting..."
    else: 
        # not a last name match
        pass
    # COUNTS?  how many hits did we get?
    # wrapup and append all reporting strings
    Output.rectext.append('\n'.join(results))                   # write results data one line at a time
    Output.datatext.append(''.join(dataresults))                   # write results data one line at a time
    Flags.isMatch = False
    Flags.artHasEmail = False
    Flags.emailmatch = False
    return XMLnodes.newroot


    
    
def getNameParts (curnameitems):
    ''' getNameParts() function takes a name string from SearchAuthorName list via main() and breaks it into
    component name parts and URI string, and stores it in SearchAuthorName one-shot name part references

    dev?  add hyphen in forename functionality: initials ZH when forename is Zhang-Hu

    '''
    #declarations
    uristring = ""
    templastname = ""
    newfirstname = ""
    newlastname = ""
    remainingnamestring = ""
    firstandlast = ""
    currentURI = ""
    currentdept = ""
    currentdeptname = ""
    suffix = ""
    authname = []
    curnameparts = len(curnameitems)
    uristring = curnameitems[0]
    currentname = curnameitems[1]
    if curnameparts > 2:
        emailstring = curnameitems[2]
    else:
        emailstring = ""
    # begin deconstruction
    #print currentname
    lenfullname = (len(currentname))                       # get length of fullname string
    commapos = currentname.find(",")                       #look for comma postion in string, everything to next comma is lastname
    #newlastname = currentname[:commapos]                   #get last name

    newlastname =  currentname[:commapos]

#    newlastname = ('%r' % currentname[:commapos])
    
    utflastname = newlastname.encode('utf-8')
    #newlastnamestring.decode('ISO-8859-1')
    #print newlastnamestring
    
    #spaceinlastname = newlastname.find(" ")
    #if spaceinlastname <> 0:
        #print "SPACE IN LASTNAME"
    #hypheninlastname = newlastname.find("-")
    #if hypheninlastname <> 0:
        #print "HYPHEN IN LASTNAME"        
    
    remainingnamestring = (currentname[(commapos+1):])      #prep remaining string
    firstandlast = remainingnamestring.strip()
    #search for comma in remaining name string, pull suffix from end
    sufcommapos = firstandlast.rfind(",")                       #look for comma postion in string
    if sufcommapos <> -1:                                       #suffix found!
        newsuffix = (firstandlast[(sufcommapos+1):])
        suffix = newsuffix.strip()
        firstandlast = firstandlast[:sufcommapos]               #modify firstandlast to exclude suffix
    # resume breakdown of first and middle
    spacepos = firstandlast.find(" ")                      #look for space in remaining name string
    if spacepos == -1:
        #no additional space found, take entire string from 0 to lenfirstandlast
        newfirstname = firstandlast
        newmiddlename = ""
    else:
        #space was found, strip first name out
        newfirstname = firstandlast[:spacepos]
        remainingmidname = firstandlast[spacepos:]
        #check to see if we can get another middle name and test for suffix
        midorsuffix = remainingmidname.strip()
        midspacepos = midorsuffix.rfind(" ")
        if midspacepos == -1:                                 #expected, means no second mid or suffix, process for period
            newmidname = midorsuffix
            midperiodpos = newmidname.rfind(".")
            if midperiodpos == -1:                         #period not found
                newmiddlename = newmidname
            else:
                newmiddlename = newmidname[:midperiodpos]  #period found, strip it
        else:                                                 #surprise, second middle name or suffix.  pull first middle and process second
            newmiddlename = midorsuffix[:midspacepos]
            remainingmid = midorsuffix[midspacepos:]
            newsecondmid = remainingmid.strip()
            secondmidperiodpos = newsecondmid.rfind(".")
            if secondmidperiodpos == -1:                         #period not found
                secondmiddlename = newsecondmid
            else:
                secondmiddlename = newsecondmid[:secondmidperiodpos]  #period found, strip it

        #all done name processing, clean up, find initial strings, create return list  

    newfirstinitial = newfirstname[0]
    if newmiddlename <> "":
        newmiddleinitial = newmiddlename[0]
    else:
        newmiddleinitial = ""
    Output.authtext.append('VIVO uri: %s\n' % (uristring))
    #rectext = rectext + ('Dept uri: %s\n' % (currentdept))
    #rectext = rectext + ('Dept name: %s\n' % (currentdeptname))
    Output.authtext.append('name variants for %s\n' % (currentname))
    Output.authtext.append('%s %s\n' % (newlastname, newfirstinitial))
    Output.authtext.append('%s %s%s\n' % (newlastname, newfirstinitial, newmiddleinitial))
    Output.authtext.append('%s %s\n' % (newlastname, newfirstname))
    Output.authtext.append('%s %s %s\n' % (newlastname, newfirstname, newmiddlename))
    #load function parameters
    SearchAuthorName.lastname = newlastname.strip()
    SearchAuthorName.firstinit = newfirstinitial.strip()
    SearchAuthorName.midinit = newmiddleinitial.strip()
    SearchAuthorName.firstname = newfirstname.strip()
    SearchAuthorName.middlename = newmiddlename.strip()
    SearchAuthorName.authuri = uristring.strip()
    SearchAuthorName.suffix = suffix.strip()
    SearchAuthorName.authemail = emailstring.strip()
    SearchAuthorName.authname = [SearchAuthorName.lastname, SearchAuthorName.firstinit, SearchAuthorName.midinit, SearchAuthorName.firstname, SearchAuthorName.middlename, SearchAuthorName.suffix, SearchAuthorName.authuri, SearchAuthorName.authemail]
    return SearchAuthorName.authname

def cmdLineUINameFile():
    ''' cmdLineUINameFile() function provides command line options for NameFile xml ingest
    pulls from global variables at the top
    provides manual entry choice to enter a single name
    '''
    
    print "Type your choice for NAMELIST and press ENTER: "
    print "1 - CALS"
    print "2 - VET"
    print "3 - WEILL"
    print "4 - ALL VIVO FACULTY"
    print "5 - ALL VIVO EMPLOYEES"
    print "6 - ALL VIVO WITH EMAIL"
    print "9 - MANUAL ENTRY"
    namelistchoice = raw_input (">>")

    if namelistchoice == "1":
        namefile = calsnamefile
    elif namelistchoice == "2":
        namefile = vetnamefile
    elif namelistchoice == "3":
        namefile = weillnamefile
    elif namelistchoice == "4":
        namefile = rbnnamefile
    elif namelistchoice == "6":
        namefile = emailnamefile
    elif namelistchoice == "9":
        namefile = "from manual entry"
    return namefile

def cmdLineUIInFile():
    ''' cmdLineUIInFile() function provides command line options for Infile (pubs list) xml ingest
    pulls from global variables at the top
    provides manual entry choice to enter a single file name
    '''
    print "Type your choice for PubMed source file and press ENTER: "
    print "a - CALS"
    print "b - VET"
    print "c - WEILL"
    print "d - ALL CORNELL PUBS (RBD)"
    print "e - ALL UF VIVO PUBS (RBD)"
    print "z - MANUAL ENTRY"
    infilechoice = raw_input (">>")

    if infilechoice == "a":
        infile = calsinfile
    elif infilechoice == "b":
        infile = vetinfile
    elif infilechoice == "c":
        infile = weillinfile
    elif infilechoice == "d":
        infile = curbdinfile
    elif infilechoice == "d":
        infile = ufrbdinfile
    elif infilechoice == "z":
        infile = raw_input ("enter a valid PubMed input file")
    else:
        pass
    return infile



 
def get_PMIDlist(query, email='cmw48@cornell.edu', tool='SimonsPythonQuery', database='pubmed'):
    #setup dictionary for eUtils parameters
    params = {
    'db':database,
    'tool':tool,
    'email':email,
    'term':query,
    'usehistory':'n',
    'mindate':'1990',
    'maxdate':'2010',    
    'retmax':100
    }

    # try to resolve the PubMed ID of the DOI
    url = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?' +     urllib.urlencode(params)
    data = urllib.urlopen(url).read()
    #print data
    # parse XML output from PubMed...
    xmldoc = minidom.parseString(data)
    ids = xmldoc.getElementsByTagName('Id')

    # nothing found, exit
    if len(ids) == 0:
        print "PMIDNotFound"
        ids = []
        data = None
    else:
        print "found " + str(len(ids)) + " matching UIDs"

        # get IDs
        for c in range(len(ids)):
            print str(c)
            FoundAuthorName.PMIDlist.append (ids[c].childNodes[0].data)
            print FoundAuthorName.PMIDlist[c]
    return FoundAuthorName.PMIDlist

def get_PubRecord(pmid, email='cmw48@cornell.edu', tool='SimonsPythonQuery', database='pubmed'):
    print pmid
    params = {
    'db':database,
    'tool':tool,
    'email':email,
    'id':pmid,
    'retmode':'xml'
    }
    
    # get citation info:
    url = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?' +     urllib.urlencode(params)
    print url
    data = urllib.urlopen(url).read()
    return data
 
def text_output(xml):
    """Makes a simple text output from the XML returned from efetch"""
 
    xmldoc = minidom.parseString(xml)
    nodetext = []
    title = xmldoc.getElementsByTagName('ArticleTitle')[0]
    title = title.childNodes[0].data
 
    abstract = xmldoc.getElementsByTagName('AbstractText')[0]
    abstract = abstract.childNodes[0].data
 
    authors = xmldoc.getElementsByTagName('AuthorList')[0]
    authors = authors.getElementsByTagName('Author')
    authorlist = []
    for author in authors:
        #load data array from XML
        tagnames = ['LastName', 'Initials']
        for n in range(len(tagnames)):
            nodetext.append(author.getElementsByTagName(tagnames[n])[0].childNodes[0].data)
        author = '%s, %s' % (nodetext[0], nodetext[1])
        authorlist.append(author)
 
        journalinfo = xmldoc.getElementsByTagName('Journal')[0]
        journal = journalinfo.getElementsByTagName('Title')[0].childNodes[0].data
        journalinfo = journalinfo.getElementsByTagName('JournalIssue')[0]

        #volume = journalinfo.getElementsByTagName('Volume')[0].childNodes[0].data
        volume = "no vol"
        issue = "no issue"

        #issue = journalinfo.getElementsByTagName('Issue')[0].childNodes[0].data
        year = journalinfo.getElementsByTagName('Year')[0].childNodes[0].data
 
        # this is a bit odd?
        #pages = xmldoc.getElementsByTagName('MedlinePgn')[0].childNodes[0].data
        pages = "no pages"
 
        output= []
        output.append(title)
        output.append('') #empty line
        output.append(', '.join(authorlist))
        output.append( '%s %s, %s (%s):%s' % (journal, year, volume, issue, pages) )
        output.append('') #empty line
        output.append(abstract)
        return output
 



# main begin---
def main():
    ''' main() function has the following responsibilities:
    a) get number of records in pubmed set
    b) return list of names and URIs from namefile using target parser (longnamelist[])
    c) concatenate name and URI and append to namelist[]
    d) open output file for text output and print header, timestamp start
    e) iterate over namelist
       i) call getnameparts function to process and return author name parts
       ii) call getPMrecs to iterate through pubsfile and return name matches
    f) output data to text files and timestamp finish
    g) close output files'''
    print "intitializing..."
    # declare local variables 
    singlename = -1
    partialmatch = False                         #accept partial lastname matches?
    results = []                                #list/string for output
    numnames = 0
    numVIVOnames = 0
    authorname = []
    finduri = ""
    NameList = []
    infile = ""
    namefile = ""
    startdate = ""
    startdate = str(datetime.datetime.today())
    namefile = cmdLineUINameFile()
    infile = cmdLineUIInFile()

    # input section - get data from         
    if namefile <> "from manual entry":

        #use target parsing to return a list of all names from the VIVO file, so we can get a count
        print "reading names..."
        namexmlout = open(nameXMLfile, 'w')
        namexmlout.write('<?xml version="1.0"?>')
        namerecstatus = getNamerecs(namefile, namexmlout)
        print namerecstatus
        numVIVOnames = len(SearchAuthorName.searchname)
        print "total records processed: " + str(numVIVOnames)

                
    else:

        lastnameinput = raw_input ("enter a name: Lastname, Firstname Middlename")
        VIVOuriinput = raw_input ("enter a valid VIVO uri for this name")
        emailinput = raw_input ("enter a valid email for this name")
        NameList.append(VIVOuriinput + ", " + lastnameinput)
        numVIVOnames = 1
   
        #raise MyError("Bad input.")
        
    # use Xpath to return a list of all titles to give us total number of records in the PUBMED file
    ''' note: this is just for the purposes of the header file - if performance related issues arise, then remove'''
    #print "counting PubMed records..."

    
    #numrecs = getPMRecordCount(infile)
    #    tree = etree.parse(infile)
    #title = tree.xpath('/PubmedArticleSet/PubmedArticle/MedlineCitation/PMID')
    #numrecs = len(title)
    #title = []
    #tree = []
    print ("counted %s pubmed records...." % (numrecs))
    # header for text output file    
    print ('indexing %s names in %s...' % (numVIVOnames, infile))
    Output.header.append('INSITU Publications Indexing Tool Results - Date: %s \n' % (startdate))
    Output.header.append ('indexing a total of %s names in %s\n' % (numVIVOnames, namefile))
    out = codecs.open(outputtextfile, 'w')                              # write to file
    dataout = open(datatextfile, 'w')                              # write to file
    out.write('\n'.join(Output.header).encode('utf-8'))             # write output header at top of report
    out.write('\n ------------------------------------------------------------------------------------ \n\n')
    xmlout = open(outputXMLfile, 'w')
    xmlout.write('<?xml version="1.0"?>')
    xmlexc = open(exceptXMLfile, 'w')
    xmlexc.write('<?xml version="1.0"?>')

    # for all SearchNames stored in SearchAuthorNames, iterate over the pubs comparison getPMrecs 

    for a in range(numVIVOnames):  #change value for testing smaller sets, numVIVOnames for full load
        curnameitems = SearchAuthorName.searchname[a]
        Output.authtext.append('searching %s for %s: \n\n' % (infile, curnameitems[1]))
        authorname = getNameParts(curnameitems)
        print ('person %s of %s: %s %s%s...  analyzing %s records' % (str(a), str(numVIVOnames),SearchAuthorName.lastname, SearchAuthorName.firstinit, SearchAuthorName.midinit, numrecs))
        # put together query string based on LASTNAME, F
        query1 = '('
        author = ('%s %s' % (SearchAuthorName.lastname, SearchAuthorName.firstinit))
        query3 = '[Author]'
        query4 = ' AND '
        query5 = '(Cornell[Affiliation] OR Ithaca[Affiliation] OR Weill[Affiliation] OR Geneva[Affiliation])'
        querystring = query1 + author + query3 + query4 + query5
        PMIDlist = get_PMIDlist(querystring)
        if PMIDlist is not None:
            FoundAuthorName.numofPMID = len(PMIDlist)
            for rec in range(FoundAuthorName.numofPMID):
                print "PMID detected: " + FoundAuthorName.PMIDlist[rec]
                pubmedrec = get_PubRecord(FoundAuthorName.PMIDlist[rec])
                #for line in text_output(citation):
                #    print line
                PMStrings = getPMrecs(pubmedrec, xmlout, xmlexc, squelch, partialmatch)
                numresults = Counts.match
                # prepare output string
                out.write (''.join(Output.authtext).encode('utf-8'))
        else:
            Counts.match = 0
        Output.rectext.append('INSITU found %s records in the dataset with LastName %s and FirstInitial %s\n' % (FoundAuthorName.numofPMID, SearchAuthorName.lastname, SearchAuthorName.firstinit ))        
        Output.rectext.append('and returned %s possible matches based on name parts and email strings.\n' % (Counts.match))
        Output.rectext.append('out of a total %s records in %s: \n\n' % (Counts.recs, infile))
        Counts.match = 0
        Counts.lastmatch = 0                      
        out.write (''.join(Output.rectext).encode('utf-8'))
        # write results data one line at a time
        dataout.write (''.join(Output.datatext).encode('utf-8'))
        out.write('\n ------------------------------------------------------------------------------------ \n\n')
        Output.authtext = []
        Output.rectext = []
        Output.datatext = []
        PMStrings = []
        FoundAuthorName.numofPMID = 0
    #all done?  timestamp file with stop time
    finishdate = ""
    finishdate = str(datetime.datetime.today())       
    Output.footer.append("process ended at" + finishdate)
    out.write('%s \n' % (Output.footer))                   # write output footer at bottom of report
    out.close()
    xmlout.close()
    xmlexc.close()
    namexmlout.close()
    dataout.close()
    raise MyError("There aren't any more records to look at.")
                         
if __name__=="__main__":
    try:
        main()
    except AttributeError:
        print "Hey, another attribute error!"
        #print "here's the current value of foundlastname: " + foundlastname       
        #print "here's the current value of foundforename: " + foundforename
        traceback.print_exc()
        print "I'm not exactly sure what to do."
    except MyError as e:
        print "Terminating process.", e.value
    else:        
        print 'An unhandled exception occured!'
        traceback.print_exc()
    finally: 
        p = raw_input ("press ENTER to continue:")
